{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# working with arrays, has functionsin domain of linear algebra, fourier transform, and matrices\n",
    "import pandas as pd\n",
    "# pd is used for data processing\n",
    "import matplotlib.pyplot as plt\n",
    "#plt provides an implicit, MATLAB-like, way of plotting\n",
    "import seaborn as sns\n",
    "#sns is a data visualization library based on matplotlib\n",
    "\n",
    "data=pd.read_csv('/Users/eden_zoo/Desktop/Certificate in Data Analytics/CIND820 Capstone Project/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histograms above show that there is very few outlier compared to the data size\n",
    "#Histograms above show that in majority of attributes, the fraud distribution line fitted by sparse blue histograms distinguishes from the orange legitimate distribution. \n",
    "\n",
    "#Looking at the histograms, V1-V28 all seem scaled, but not amount and time. So the next step will be scaling amount and time.\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rbst_scaler=RobustScaler() # robustscaler is less prone to outliers\n",
    "\n",
    "data['scaled_time']=rbst_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "data['scaled_amount']=rbst_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "\n",
    "data.drop(['Time','Amount'],axis=1,inplace=True)\n",
    "\n",
    "scaled_time=data['scaled_time']\n",
    "scaled_amount=data['scaled_amount']\n",
    "\n",
    "data.drop(['scaled_time','scaled_amount'],axis=1,inplace=True)\n",
    "data.insert(0,'scaled_amount',scaled_amount)\n",
    "data.insert(1,'scaled_time',scaled_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "#from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis=1 drops labels from columns.\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold stratified split for cross-validation\n",
    "sss = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling the majority with RUS - minority:majority = 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://localhost:8888/notebooks/Desktop/Certificate%20in%20Data%20Analytics/CIND820%20Capstone%20Project/Credit%20Card%20Fraud%20Detection%20-%20Random%20Forest.ipynb#Undersampling-the-majority-with-RUS---minority:majority-=-1:1from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "# print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# define hyperparameters\n",
    "n_estimators = [10, 50, 100]\n",
    "max_features = ['sqrt', 'log2']\n",
    "class_weight =[None, 'balanced', 'balanced_subsample']\n",
    "\n",
    "# hyperparameter tuning\n",
    "best_model={'n_estimators':-1,'max_features':\"-1\", 'class_weight': \"-1\"}\n",
    "best_result=0\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train_sampled, y_train_sampled = rus.fit_resample(original_Xtrain, original_ytrain)\n",
    "    \n",
    "    counter = Counter(y_train_sampled)\n",
    "    print(counter)\n",
    "    \n",
    "    for n in n_estimators:\n",
    "        for m_f in max_features:\n",
    "            for c_w in class_weight:\n",
    "                clf = RandomForestClassifier(random_state=0,n_estimators=n,max_features=m_f,class_weight=c_w).fit(X_train_sampled, y_train_sampled)\n",
    "                results=clf.predict(original_Xtest)\n",
    "                f1=f1_score(original_ytest,results)\n",
    "                if f1 > best_result:\n",
    "                    best_result=f1\n",
    "                    best_model['n_estimators']=n\n",
    "                    best_model['max_features']=m_f\n",
    "                    best_model['class_weight']=c_w\n",
    "    # ‘liblinear’ and ‘saga’ both handle L1 penalty. ‘liblinear’ is good for small dataet, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "    print(best_model)\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=0,n_estimators=best_model['n_estimators'],max_features=best_model['max_features'],class_weight=best_model['class_weight']).fit(X_train_sampled, y_train_sampled)\n",
    "    results=clf.predict(original_Xtest)\n",
    "    re=precision_recall_fscore_support(original_ytest, results, average='macro')\n",
    "    precision=re[0]\n",
    "    recall=re[1]\n",
    "    fscore=re[2]\n",
    "    #f1=f1_score(original_ytest,results)\n",
    "    print(\"precision={}, recall={}, f1={}\".format(precision,recall,fscore))\n",
    "    \n",
    "#     clf = LogisticRegression(random_state=0,C=best_model['C'],penalty=best_model['penalty'],solver='saga',max_iter=3000).fit(X_train_sampled, y_train_sampled)\n",
    "#     results=clf.predict(original_Xtest)\n",
    "#     re=precision_recall_fscore_support(original_ytest, results, average='macro')\n",
    "#     precision=re[0]\n",
    "#     recall=re[1]\n",
    "#     fscore=re[2]\n",
    "#     #f1=f1_score(original_ytest,results)\n",
    "#     print(\"precision={}, recall={}, f1={}\".format(precision,recall,fscore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling the majority with RUS - minority:majority = 1:9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=0.11,random_state=42)\n",
    "\n",
    "# define hyperparameters\n",
    "n_estimators = [10, 50, 100]\n",
    "max_features = ['sqrt', 'log2']\n",
    "class_weight =[None, 'balanced', 'balanced_subsample']\n",
    "\n",
    "# hyperparameter tuning\n",
    "best_model={'n_estimators':-1,'max_features':\"-1\", 'class_weight': \"-1\"}\n",
    "best_result=0\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train_sampled, y_train_sampled = rus.fit_resample(original_Xtrain, original_ytrain)\n",
    "    \n",
    "    counter = Counter(y_train_sampled)\n",
    "    print(counter)\n",
    "    \n",
    "    for n in n_estimators:\n",
    "        for m_f in max_features:\n",
    "            for c_w in class_weight:\n",
    "                clf = RandomForestClassifier(random_state=0,n_estimators=n,max_features=m_f,class_weight=c_w).fit(X_train_sampled, y_train_sampled)\n",
    "                results=clf.predict(original_Xtest)\n",
    "                f1=f1_score(original_ytest,results)\n",
    "                if f1 > best_result:\n",
    "                    best_result=f1\n",
    "                    best_model['n_estimators']=n\n",
    "                    best_model['max_features']=m_f\n",
    "                    best_model['class_weight']=c_w\n",
    "    # ‘liblinear’ and ‘saga’ both handle L1 penalty. ‘liblinear’ is good for small dataet, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "    print(best_model)\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=0,n_estimators=best_model['n_estimators'],max_features=best_model['max_features'],class_weight=best_model['class_weight']).fit(X_train_sampled, y_train_sampled)\n",
    "    results=clf.predict(original_Xtest)\n",
    "    re=precision_recall_fscore_support(original_ytest, results, average='macro')\n",
    "    precision=re[0]\n",
    "    recall=re[1]\n",
    "    fscore=re[2]\n",
    "    #f1=f1_score(original_ytest,results)\n",
    "    print(\"precision={}, recall={}, f1={}\".format(precision,recall,fscore))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     clf = LogisticRegression(random_state=0,C=best_model['C'],penalty=best_model['penalty'],solver='saga',max_iter=3000).fit(X_train_sampled, y_train_sampled)\n",
    "#     results=clf.predict(original_Xtest)\n",
    "#     re=precision_recall_fscore_support(original_ytest, results, average='macro')\n",
    "#     precision=re[0]\n",
    "#     recall=re[1]\n",
    "#     fscore=re[2]\n",
    "#     #f1=f1_score(original_ytest,results)\n",
    "#     print(\"precision={}, recall={}, f1={}\".format(precision,recall,fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling the minority with SMOTE - minority:majority = 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "\n",
    "oversampler_smote = SMOTE(random_state=42)\n",
    "\n",
    "# define hyperparameters\n",
    "n_estimators = [10, 50, 100]\n",
    "max_features = ['sqrt', 'log2']\n",
    "class_weight =[None, 'balanced', 'balanced_subsample']\n",
    "\n",
    "# hyperparameter tuning\n",
    "best_model={'n_estimators':-1,'max_features':\"-1\", 'class_weight': \"-1\"}\n",
    "best_result=0\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train_sampled, y_train_sampled = oversampler_smote.fit_resample(original_Xtrain, original_ytrain)\n",
    "    \n",
    "    counter = Counter(y_train_sampled)\n",
    "    print(counter)\n",
    "    \n",
    "    for n in n_estimators:\n",
    "        for m_f in max_features:\n",
    "            for c_w in class_weight:\n",
    "                clf = RandomForestClassifier(random_state=0,n_estimators=n,max_features=m_f,class_weight=c_w).fit(X_train_sampled, y_train_sampled)\n",
    "                results=clf.predict(original_Xtest)\n",
    "                f1=f1_score(original_ytest,results)\n",
    "                if f1 > best_result:\n",
    "                    best_result=f1\n",
    "                    best_model['n_estimators']=n\n",
    "                    best_model['max_features']=m_f\n",
    "                    best_model['class_weight']=c_w\n",
    "    # ‘liblinear’ and ‘saga’ both handle L1 penalty. ‘liblinear’ is good for small dataet, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "    print(best_model)\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=0,n_estimators=best_model['n_estimators'],max_features=best_model['max_features'],class_weight=best_model['class_weight']).fit(X_train_sampled, y_train_sampled)\n",
    "    results=clf.predict(original_Xtest)\n",
    "    re=precision_recall_fscore_support(original_ytest, results, average='macro')\n",
    "    precision=re[0]\n",
    "    recall=re[1]\n",
    "    fscore=re[2]\n",
    "    #f1=f1_score(original_ytest,results)\n",
    "    print(\"precision={}, recall={}, f1={}\".format(precision,recall,fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine undersampling (RUS) with oversampling (SMOTE) - minority:majority = 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.05,random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=1,random_state=42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# define hyperparameters\n",
    "n_estimators = [10, 50, 100]\n",
    "max_features = ['sqrt', 'log2']\n",
    "class_weight =[None, 'balanced', 'balanced_subsample']\n",
    "\n",
    "# hyperparameter tuning\n",
    "best_model={'n_estimators':-1,'max_features':\"-1\", 'class_weight': \"-1\"}\n",
    "best_result=0\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train_sampled, y_train_sampled = pipeline.fit_resample(original_Xtrain, original_ytrain)\n",
    "    \n",
    "    counter = Counter(y_train_sampled)\n",
    "    print(counter)\n",
    "    \n",
    "    for n in n_estimators:\n",
    "        for m_f in max_features:\n",
    "            for c_w in class_weight:\n",
    "                clf = RandomForestClassifier(random_state=0,n_estimators=n,max_features=m_f,class_weight=c_w).fit(X_train_sampled, y_train_sampled)\n",
    "                results=clf.predict(original_Xtest)\n",
    "                f1=f1_score(original_ytest,results)\n",
    "                if f1 > best_result:\n",
    "                    best_result=f1\n",
    "                    best_model['n_estimators']=n\n",
    "                    best_model['max_features']=m_f\n",
    "                    best_model['class_weight']=c_w\n",
    "    # ‘liblinear’ and ‘saga’ both handle L1 penalty. ‘liblinear’ is good for small dataet, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "    print(best_model)\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=0,n_estimators=best_model['n_estimators'],max_features=best_model['max_features'],class_weight=best_model['class_weight']).fit(X_train_sampled, y_train_sampled)\n",
    "    results=clf.predict(original_Xtest)\n",
    "    re=precision_recall_fscore_support(original_ytest, results, average='macro')\n",
    "    precision=re[0]\n",
    "    recall=re[1]\n",
    "    fscore=re[2]\n",
    "    #f1=f1_score(original_ytest,results)\n",
    "    print(\"precision={}, recall={}, f1={}\".format(precision,recall,fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
