{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# working with arrays, has functionsin domain of linear algebra, fourier transform, and matrices\n",
    "import pandas as pd\n",
    "# pd is used for data processing\n",
    "import matplotlib.pyplot as plt\n",
    "#plt provides an implicit, MATLAB-like, way of plotting\n",
    "import seaborn as sns\n",
    "#sns is a data visualization library based on matplotlib\n",
    "\n",
    "data=pd.read_csv('/Users/eden_zoo/Desktop/Certificate in Data Analytics/CIND820 Capstone Project/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histograms above show that there is very few outlier compared to the data size\n",
    "#Histograms above show that in majority of attributes, the fraud distribution line fitted by sparse blue histograms distinguishes from the orange legitimate distribution. \n",
    "\n",
    "#Looking at the histograms, V1-V28 all seem scaled, but not amount and time. So the next step will be scaling amount and time.\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rbst_scaler=RobustScaler() # robustscaler is less prone to outliers\n",
    "\n",
    "data['scaled_time']=rbst_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "data['scaled_amount']=rbst_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "\n",
    "data.drop(['Time','Amount'],axis=1,inplace=True)\n",
    "\n",
    "scaled_time=data['scaled_time']\n",
    "scaled_amount=data['scaled_amount']\n",
    "\n",
    "data.drop(['scaled_time','scaled_amount'],axis=1,inplace=True)\n",
    "data.insert(0,'scaled_amount',scaled_amount)\n",
    "data.insert(1,'scaled_time',scaled_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "#from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis=1 drops labels from columns.\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-fold stratified split for cross-validation\n",
    "sss = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling the majority with RUS - minority:majority = 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "precision=0.6940073740973967, recall=0.9029324779724863, f1=0.7616569844659149\n",
      "{'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "precision=0.8305767004777609, recall=0.9238643224890872, f1=0.871426354274645\n",
      "{'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "precision=0.8027877215446131, recall=0.9229945622974232, f1=0.8528880245856063\n",
      "{'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "precision=0.6264348647610047, recall=0.9010124405705514, f1=0.6915729120290709\n",
      "{'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "precision=0.7038391551754967, recall=0.9173209723190756, f1=0.7736534217761801\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for logistic regression\n",
    "Cs=[0.001, 0.01, 0.1, 1, 10, 100, 1000] #=np.logspace(-3,3,7)\n",
    "penalty = [\"l1\",\"l2\"]\n",
    "solver = ['saga', 'liblinear'] #only two optimizers work for both l1 and l2 regularizations\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# hyperparameter tuning\n",
    "best_model={'C':-1,'penalty':\"-1\", 'solver':'unknown'}\n",
    "best_result=0\n",
    "    \n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train_sampled, y_train_sampled = rus.fit_resample(original_Xtrain, original_ytrain)\n",
    " \n",
    "    for c in Cs:\n",
    "        for p in penalty:\n",
    "            for s in solver:\n",
    "                clf = LogisticRegression(random_state=0,C=c,penalty=p,solver=s,max_iter=3000).fit(X_train_sampled, y_train_sampled)\n",
    "                results=clf.predict(original_Xtest)\n",
    "                f1=f1_score(original_ytest,results)\n",
    "                if f1 > best_result:\n",
    "                    best_result=f1\n",
    "                    best_model['C']=c\n",
    "                    best_model['penalty']=p\n",
    "                    best_model['solver']=s\n",
    "    # ‘liblinear’ and ‘saga’ both handle L1 penalty. ‘liblinear’ is good for small dataet, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "    print(best_model)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0,C=best_model['C'],penalty=best_model['penalty'],solver=best_model['solver'],max_iter=3000).fit(X_train_sampled, y_train_sampled)\n",
    "    results=clf.predict(original_Xtest)\n",
    "    re=precision_recall_fscore_support(original_ytest, results, average='macro')\n",
    "    precision=re[0]\n",
    "    recall=re[1]\n",
    "    fscore=re[2]\n",
    "    #f1=f1_score(original_ytest,results)\n",
    "    print(\"precision={}, recall={}, f1={}\".format(precision,recall,fscore))\n",
    "#     clf = LogisticRegression(random_state=0,C=best_model['C'],penalty=best_model['penalty'],solver='saga',max_iter=3000).fit(X_train_sampled, y_train_sampled)\n",
    "#     results=clf.predict(original_Xtest)\n",
    "#     re=precision_recall_fscore_support(original_ytest, results, average='macro')\n",
    "#     precision=re[0]\n",
    "#     recall=re[1]\n",
    "#     fscore=re[2]\n",
    "#     #f1=f1_score(original_ytest,results)\n",
    "#     print(\"precision={}, recall={}, f1={}\".format(precision,recall,fscore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling the majority with RUS - minority:majority = 1:9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "precision=0.8772575227769617, recall=0.8886690622881116, f1=0.8828779346586362\n",
      "{'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n",
      "precision=0.8892647878520579, recall=0.9088886686181941, f1=0.8988345125870449\n"
     ]
    }
   ],
   "source": [
    "Cs=[0.001, 0.01, 0.1, 1, 10, 100, 1000] #=np.logspace(-3,3,7)\n",
    "penalty = [\"l1\",\"l2\"]\n",
    "solver = ['saga', 'liblinear'] #only two optimizers work for both l1 and l2 regularizations\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1,random_state=42)\n",
    "\n",
    "# hyperparameter tuning\n",
    "best_model={'C':-1,'penalty':\"-1\", 'solver':'unknown'}\n",
    "best_result=0\n",
    "    \n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train_sampled, y_train_sampled = rus.fit_resample(original_Xtrain, original_ytrain)\n",
    " \n",
    "    for c in Cs:\n",
    "        for p in penalty:\n",
    "            for s in solver:\n",
    "                clf = LogisticRegression(random_state=0,C=c,penalty=p,solver=s,max_iter=3000).fit(X_train_sampled, y_train_sampled)\n",
    "                results=clf.predict(original_Xtest)\n",
    "                f1=f1_score(original_ytest,results)\n",
    "                if f1 > best_result:\n",
    "                    best_result=f1\n",
    "                    best_model['C']=c\n",
    "                    best_model['penalty']=p\n",
    "                    best_model['solver']=s\n",
    "    # ‘liblinear’ and ‘saga’ both handle L1 penalty. ‘liblinear’ is good for small dataet, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "    print(best_model)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0,C=best_model['C'],penalty=best_model['penalty'],solver=best_model['solver'],max_iter=3000).fit(X_train_sampled, y_train_sampled)\n",
    "    results=clf.predict(original_Xtest)\n",
    "    re=precision_recall_fscore_support(original_ytest, results, average='macro')\n",
    "    precision=re[0]\n",
    "    recall=re[1]\n",
    "    fscore=re[2]\n",
    "    #f1=f1_score(original_ytest,results)\n",
    "    print(\"precision={}, recall={}, f1={}\".format(precision,recall,fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine undersampling (RUS) with oversampling (SMOTE) - minority:majority = 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.05,random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=1,random_state=42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "# transform the dataset    \n",
    "    X_train_sampled, y_train_sampled = pipeline.fit_resample(original_Xtrain, original_ytrain)\n",
    "    \n",
    "    counter = Counter(y_train_sampled)\n",
    "    print(counter)\n",
    "\n",
    "    clf = LogisticRegression(random_state=0,C=best_model['C'],penalty=best_model['penalty'],solver=best_model['solver'],max_iter=3000).fit(X_train_sampled, y_train_sampled)\n",
    "    results=clf.predict(original_Xtest)\n",
    "    re=precision_recall_fscore_support(original_ytest, results, average='macro')\n",
    "    precision=re[0]\n",
    "    recall=re[1]\n",
    "    fscore=re[2]\n",
    "    print(\"precision={}, recall={}, f1={}\".format(precision,recall,fscore))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
